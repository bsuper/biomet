{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH4 Cross Validation\n",
    "\n",
    "### Train Features\n",
    "1. land surface temp (wp_LST.day)\n",
    "2. sensible heat flux (wp_le)\n",
    "3. latent heat flux (wp_h)\n",
    "4. net radiation (net_rad)\n",
    "5. avg air temp (avg_air_temp)\n",
    "\n",
    "### Performance\n",
    "Compared to regressions on other values, CH4 Methane Regression performs poorly. Looking at the feature correlation plots, we see that there aren't any variables that are strongly correlated with ch4_gf. Thus, this poor performance is not surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import exp\n",
    "import regression as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_air_temp</th>\n",
       "      <th>avg_soil_temp</th>\n",
       "      <th>doy</th>\n",
       "      <th>net_rad</th>\n",
       "      <th>year</th>\n",
       "      <th>wp_ch4_gf</th>\n",
       "      <th>wp_co2_gf</th>\n",
       "      <th>wp_er</th>\n",
       "      <th>wp_gpp</th>\n",
       "      <th>wp_h</th>\n",
       "      <th>...</th>\n",
       "      <th>mb_bnd2</th>\n",
       "      <th>mb_bnd3</th>\n",
       "      <th>mb_bnd7</th>\n",
       "      <th>mb_evi</th>\n",
       "      <th>mb_lswi</th>\n",
       "      <th>mb_ndvi</th>\n",
       "      <th>wp_LST.day</th>\n",
       "      <th>wp_LST.night</th>\n",
       "      <th>mb_LST.day</th>\n",
       "      <th>mb_LST.night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>195</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4332.368657</td>\n",
       "      <td>-304.542172</td>\n",
       "      <td>145.072376</td>\n",
       "      <td>-449.614548</td>\n",
       "      <td>1447.549899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187575</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>0.053137</td>\n",
       "      <td>0.298162</td>\n",
       "      <td>0.562370</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>29.61</td>\n",
       "      <td>17.2850</td>\n",
       "      <td>26.3350</td>\n",
       "      <td>18.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.3</td>\n",
       "      <td>21.8</td>\n",
       "      <td>196</td>\n",
       "      <td>189.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5305.896768</td>\n",
       "      <td>-335.648791</td>\n",
       "      <td>150.278671</td>\n",
       "      <td>-485.927462</td>\n",
       "      <td>1921.833137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186562</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.051306</td>\n",
       "      <td>0.296544</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>29.63</td>\n",
       "      <td>17.2325</td>\n",
       "      <td>26.4075</td>\n",
       "      <td>18.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>197</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>6215.371936</td>\n",
       "      <td>-313.150966</td>\n",
       "      <td>158.307017</td>\n",
       "      <td>-471.457982</td>\n",
       "      <td>1176.374322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185550</td>\n",
       "      <td>0.023925</td>\n",
       "      <td>0.049475</td>\n",
       "      <td>0.294925</td>\n",
       "      <td>0.585779</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>29.65</td>\n",
       "      <td>17.1800</td>\n",
       "      <td>26.4800</td>\n",
       "      <td>18.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>198</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>7129.353337</td>\n",
       "      <td>-339.900067</td>\n",
       "      <td>153.561669</td>\n",
       "      <td>-493.461736</td>\n",
       "      <td>2575.636175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184537</td>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.047644</td>\n",
       "      <td>0.293306</td>\n",
       "      <td>0.597483</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>29.67</td>\n",
       "      <td>17.1275</td>\n",
       "      <td>26.5525</td>\n",
       "      <td>18.4875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>199</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>7070.768573</td>\n",
       "      <td>-319.771564</td>\n",
       "      <td>144.053480</td>\n",
       "      <td>-463.825044</td>\n",
       "      <td>1916.081260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183525</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.291687</td>\n",
       "      <td>0.609188</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>29.69</td>\n",
       "      <td>17.0750</td>\n",
       "      <td>26.6250</td>\n",
       "      <td>18.4350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_air_temp  avg_soil_temp  doy  net_rad  year    wp_ch4_gf   wp_co2_gf  \\\n",
       "0          19.2           22.3  195    190.0  2012  4332.368657 -304.542172   \n",
       "1          19.3           21.8  196    189.0  2012  5305.896768 -335.648791   \n",
       "2          20.3           21.9  197    187.0  2012  6215.371936 -313.150966   \n",
       "3          16.8           22.4  198    186.0  2012  7129.353337 -339.900067   \n",
       "4          17.0           21.5  199    151.0  2012  7070.768573 -319.771564   \n",
       "\n",
       "        wp_er      wp_gpp         wp_h      ...        mb_bnd2   mb_bnd3  \\\n",
       "0  145.072376 -449.614548  1447.549899      ...       0.187575  0.025212   \n",
       "1  150.278671 -485.927462  1921.833137      ...       0.186562  0.024569   \n",
       "2  158.307017 -471.457982  1176.374322      ...       0.185550  0.023925   \n",
       "3  153.561669 -493.461736  2575.636175      ...       0.184537  0.023281   \n",
       "4  144.053480 -463.825044  1916.081260      ...       0.183525  0.022638   \n",
       "\n",
       "    mb_bnd7    mb_evi   mb_lswi  mb_ndvi  wp_LST.day  wp_LST.night  \\\n",
       "0  0.053137  0.298162  0.562370   0.6491       29.61       17.2850   \n",
       "1  0.051306  0.296544  0.574074   0.6504       29.63       17.2325   \n",
       "2  0.049475  0.294925  0.585779   0.6517       29.65       17.1800   \n",
       "3  0.047644  0.293306  0.597483   0.6530       29.67       17.1275   \n",
       "4  0.045812  0.291687  0.609188   0.6543       29.69       17.0750   \n",
       "\n",
       "   mb_LST.day  mb_LST.night  \n",
       "0     26.3350       18.6450  \n",
       "1     26.4075       18.5925  \n",
       "2     26.4800       18.5400  \n",
       "3     26.5525       18.4875  \n",
       "4     26.6250       18.4350  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = exp.get_exp1_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = [\"wp_LST.day\", \"wp_h\", \"wp_le\", \"net_rad\", \"avg_air_temp\"]\n",
    "X, Y = exp.featurize(df, train_cols, [\"wp_ch4_gf\"])\n",
    "X, Y, scaler = r.preprocess(X, Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Random Forests Cross Validation...\n",
      "10-fold CV Acc Mean:  0.718659261145\n",
      "CV Scores:  0.746011980089, 0.745834837801, 0.70516081643, 0.755340606135, 0.634935942478, 0.721901725789, 0.762214413658, 0.782581985518, 0.607552901038, 0.725057402518\n",
      "OOB score: 0.719886785599\n",
      "Feature Importances:\n",
      "('avg_air_temp', 0.25002115606718361)\n",
      "('wp_LST.day', 0.24702363784263143)\n",
      "('wp_le', 0.22285950120325942)\n",
      "('net_rad', 0.16492651212110004)\n",
      "('wp_h', 0.11516919276582557)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=200, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.random_forests_cross_val(X, Y, feature_names=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosted Trees Cross Validation...\n",
      "10-fold CV Acc Mean:  0.661368273893\n",
      "CV Scores:  0.655785240407, 0.646001549389, 0.654724372546, 0.697719035605, 0.607970483693, 0.654514010272, 0.714471921371, 0.775850827011, 0.525678278661, 0.680967019979\n",
      "Feature Importances:\n",
      "('wp_LST.day', 0.26324217602663841)\n",
      "('net_rad', 0.22893620135594145)\n",
      "('wp_le', 0.19333201424651439)\n",
      "('avg_air_temp', 0.16933707559041655)\n",
      "('wp_h', 0.14515253278048934)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.xgb_trees_cross_val(X, Y, feature_names=train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVC Cross Validation...\n",
      "10-fold CV Acc Mean:  -0.0310181251948\n",
      "CV Scores:  -0.0568398460287, 0.0431227012345, -0.0470083566456, 0.0254967439609, -0.00683056549759, -0.0361613297849, -0.0687493349358, -0.174653902067, 0.01559685628, -0.00415421846338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.svc_cross_val(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Neural Network Cross Validation...\n",
      "Step #1, avg. loss: 26719660.00000\n",
      "Step #501, epoch #50, avg. loss: 26093274.00000\n",
      "Step #1001, epoch #100, avg. loss: 17364868.00000\n",
      "Step #1501, epoch #150, avg. loss: 14357041.00000\n",
      "Step #2001, epoch #200, avg. loss: 12998029.00000\n",
      "Step #2501, epoch #250, avg. loss: 12328649.00000\n",
      "Step #3001, epoch #300, avg. loss: 11824319.00000\n",
      "Step #3501, epoch #350, avg. loss: 11304137.00000\n",
      "Step #4001, epoch #400, avg. loss: 10848895.00000\n",
      "Step #4501, epoch #450, avg. loss: 10366060.00000\n",
      "Step #1, avg. loss: 42104104.00000\n",
      "Step #501, epoch #50, avg. loss: 25576854.00000\n",
      "Step #1001, epoch #100, avg. loss: 17128592.00000\n",
      "Step #1501, epoch #150, avg. loss: 14122751.00000\n",
      "Step #2001, epoch #200, avg. loss: 12969589.00000\n",
      "Step #2501, epoch #250, avg. loss: 12175369.00000\n",
      "Step #3001, epoch #300, avg. loss: 11621165.00000\n",
      "Step #3501, epoch #350, avg. loss: 11152093.00000\n",
      "Step #4001, epoch #400, avg. loss: 10814477.00000\n",
      "Step #4501, epoch #450, avg. loss: 10344108.00000\n",
      "Step #1, avg. loss: 29006014.00000\n",
      "Step #501, epoch #50, avg. loss: 25284948.00000\n",
      "Step #1001, epoch #100, avg. loss: 17159304.00000\n",
      "Step #1501, epoch #150, avg. loss: 14187801.00000\n",
      "Step #2001, epoch #200, avg. loss: 12882818.00000\n",
      "Step #2501, epoch #250, avg. loss: 12131045.00000\n",
      "Step #3001, epoch #300, avg. loss: 11604768.00000\n",
      "Step #3501, epoch #350, avg. loss: 11006040.00000\n",
      "Step #4001, epoch #400, avg. loss: 10631593.00000\n",
      "Step #4501, epoch #450, avg. loss: 10270861.00000\n",
      "Step #1, avg. loss: 29987480.00000\n",
      "Step #501, epoch #50, avg. loss: 25975288.00000\n",
      "Step #1001, epoch #100, avg. loss: 17416508.00000\n",
      "Step #1501, epoch #150, avg. loss: 14388695.00000\n",
      "Step #2001, epoch #200, avg. loss: 13112158.00000\n",
      "Step #2501, epoch #250, avg. loss: 12330777.00000\n",
      "Step #3001, epoch #300, avg. loss: 11865139.00000\n",
      "Step #3501, epoch #350, avg. loss: 11252963.00000\n",
      "Step #4001, epoch #400, avg. loss: 10720298.00000\n",
      "Step #4501, epoch #450, avg. loss: 10296988.00000\n",
      "Step #1, avg. loss: 26707056.00000\n",
      "Step #501, epoch #50, avg. loss: 25599534.00000\n",
      "Step #1001, epoch #100, avg. loss: 17244164.00000\n",
      "Step #1501, epoch #150, avg. loss: 14106562.00000\n",
      "Step #2001, epoch #200, avg. loss: 12956211.00000\n",
      "Step #2501, epoch #250, avg. loss: 12315589.00000\n",
      "Step #3001, epoch #300, avg. loss: 11670974.00000\n",
      "Step #3501, epoch #350, avg. loss: 11177543.00000\n",
      "Step #4001, epoch #400, avg. loss: 10665015.00000\n",
      "Step #4501, epoch #450, avg. loss: 10303150.00000\n",
      "Step #1, avg. loss: 26044218.00000\n",
      "Step #501, epoch #50, avg. loss: 26038432.00000\n",
      "Step #1001, epoch #100, avg. loss: 17553200.00000\n",
      "Step #1501, epoch #150, avg. loss: 14254334.00000\n",
      "Step #2001, epoch #200, avg. loss: 13129274.00000\n",
      "Step #2501, epoch #250, avg. loss: 12431193.00000\n",
      "Step #3001, epoch #300, avg. loss: 11898000.00000\n",
      "Step #3501, epoch #350, avg. loss: 11322034.00000\n",
      "Step #4001, epoch #400, avg. loss: 10865336.00000\n",
      "Step #4501, epoch #450, avg. loss: 10409238.00000\n",
      "Step #1, avg. loss: 27464578.00000\n",
      "Step #501, epoch #50, avg. loss: 25335566.00000\n",
      "Step #1001, epoch #100, avg. loss: 16975958.00000\n",
      "Step #1501, epoch #150, avg. loss: 14054568.00000\n",
      "Step #2001, epoch #200, avg. loss: 12804448.00000\n",
      "Step #2501, epoch #250, avg. loss: 12125378.00000\n",
      "Step #3001, epoch #300, avg. loss: 11499197.00000\n",
      "Step #3501, epoch #350, avg. loss: 11025372.00000\n",
      "Step #4001, epoch #400, avg. loss: 10647365.00000\n",
      "Step #4501, epoch #450, avg. loss: 10151200.00000\n",
      "Step #1, avg. loss: 33046174.00000\n",
      "Step #501, epoch #50, avg. loss: 25601888.00000\n",
      "Step #1001, epoch #100, avg. loss: 17092434.00000\n",
      "Step #1501, epoch #150, avg. loss: 14327765.00000\n",
      "Step #2001, epoch #200, avg. loss: 12949002.00000\n",
      "Step #2501, epoch #250, avg. loss: 12198282.00000\n",
      "Step #3001, epoch #300, avg. loss: 11713766.00000\n",
      "Step #3501, epoch #350, avg. loss: 11185347.00000\n",
      "Step #4001, epoch #400, avg. loss: 10652066.00000\n",
      "Step #4501, epoch #450, avg. loss: 10290248.00000\n",
      "Step #1, avg. loss: 28328110.00000\n",
      "Step #501, epoch #50, avg. loss: 26493004.00000\n",
      "Step #1001, epoch #100, avg. loss: 17910956.00000\n",
      "Step #1501, epoch #150, avg. loss: 14709246.00000\n",
      "Step #2001, epoch #200, avg. loss: 13509814.00000\n",
      "Step #2501, epoch #250, avg. loss: 12745852.00000\n",
      "Step #3001, epoch #300, avg. loss: 12209453.00000\n",
      "Step #3501, epoch #350, avg. loss: 11611236.00000\n",
      "Step #4001, epoch #400, avg. loss: 11168669.00000\n",
      "Step #4501, epoch #450, avg. loss: 10767205.00000\n",
      "Step #1, avg. loss: 27479558.00000\n",
      "Step #501, epoch #50, avg. loss: 25165164.00000\n",
      "Step #1001, epoch #100, avg. loss: 16915138.00000\n",
      "Step #1501, epoch #150, avg. loss: 13954751.00000\n",
      "Step #2001, epoch #200, avg. loss: 12829366.00000\n",
      "Step #2501, epoch #250, avg. loss: 12212808.00000\n",
      "Step #3001, epoch #300, avg. loss: 11589089.00000\n",
      "Step #3501, epoch #350, avg. loss: 11070074.00000\n",
      "Step #4001, epoch #400, avg. loss: 10715826.00000\n",
      "Step #4501, epoch #450, avg. loss: 10283228.00000\n",
      "10-fold CV Acc Mean:  0.0960623113341\n",
      "CV Scores:  0.118028239172, 0.0813884102946, 0.0964489301592, 0.161196973592, 0.0552851931621, 0.139648030332, 0.0714252953619, 0.0571130990088, 0.193365661766, -0.0132767195073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlowEstimator(batch_size=100, class_weight=None,\n",
       "          continue_training=False, early_stopping_rounds=None,\n",
       "          keep_checkpoint_every_n_hours=10000, learning_rate=0.1,\n",
       "          max_to_keep=5, model_fn=<function tanh_dnn at 0x11144bb90>,\n",
       "          n_classes=0, num_cores=4, optimizer='SGD', steps=5000,\n",
       "          tf_master='', tf_random_seed=42, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.dnn_cross_val(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
